from fastapi import FastAPI
from pydantic import BaseModel
from openai import OpenAI
import os
import logging
from typing import Dict, Any

app = FastAPI()

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# üîπ D√πng OpenRouter endpoint
client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY")
)

class ChatRequest(BaseModel):
    question: str

class ChatAIService:
    """
    Service ch√≠nh x·ª≠ l√Ω chat AI - ch·ªâ s·ª≠ d·ª•ng AI ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi
    """
    
    def __init__(self):
        pass
    
    def process_question(self, question: str) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω c√¢u h·ªèi v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ t·ª´ AI
        """
        try:
            # T·∫°o prompt cho AI
            prompt = (
                f"Ng∆∞·ªùi d√πng h·ªèi: {question}\n\n"
                f"H√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch th√¢n thi·ªán, chi ti·∫øt v√† h·ªØu √≠ch b·∫±ng ti·∫øng Vi·ªát. "
                f"B·∫°n l√† tr·ª£ l√Ω AI h·ªó tr·ª£ ng∆∞·ªùi h·ªçc l·∫≠p tr√¨nh."
            )
            
            # G·ªçi AI
            ai_response = self._call_ai(prompt)
            
            return {
                "answer": ai_response,
                "data_source": "ai"
            }
            
        except Exception as e:
            logger.error(f"Error processing question: {e}")
            return {
                "answer": "Xin l·ªói, t√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i.",
                "error": str(e)
            }
    
    def _call_ai(self, prompt: str) -> str:
        """
        G·ªçi AI ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi
        """
        try:
            completion = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": (
                            "B·∫°n l√† tr·ª£ l√Ω AI h·ªó tr·ª£ ng∆∞·ªùi h·ªçc l·∫≠p tr√¨nh, n√≥i ti·∫øng Vi·ªát. "
                            "B·∫°n c√≥ th·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ l·∫≠p tr√¨nh, thu·∫≠t to√°n, c√¥ng ngh·ªá, "
                            "v√† c√°c ch·ªß ƒë·ªÅ li√™n quan ƒë·∫øn h·ªçc l·∫≠p tr√¨nh. "
                            "H√£y tr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán, chi ti·∫øt v√† h·ªØu √≠ch. "
                            "N·∫øu kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi ch√≠nh x√°c, h√£y ƒë∆∞a ra g·ª£i √Ω ho·∫∑c h∆∞·ªõng d·∫´n t√¨m hi·ªÉu th√™m."
                        )
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            return completion.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Error calling AI: {e}")
            return "Xin l·ªói, t√¥i g·∫∑p l·ªói khi t·∫°o ph·∫£n h·ªìi. Vui l√≤ng th·ª≠ l·∫°i."

# Kh·ªüi t·∫°o service
chat_ai_service = ChatAIService()

@app.post("/ask")
async def ask(request: ChatRequest):
    """
    API endpoint ch√≠nh ƒë·ªÉ x·ª≠ l√Ω c√¢u h·ªèi chat
    """
    try:
        question = request.question.strip()
        
        if not question:
            return {
                "answer": "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI h·ªó tr·ª£ h·ªçc l·∫≠p tr√¨nh. B·∫°n mu·ªën h·ªèi g√¨?",
                "suggestions": [
                    "L√†m th·∫ø n√†o ƒë·ªÉ b·∫Øt ƒë·∫ßu h·ªçc l·∫≠p tr√¨nh?",
                    "Python l√† g√¨?",
                    "C√°c kh√°i ni·ªám c∆° b·∫£n v·ªÅ thu·∫≠t to√°n",
                    "C√°ch debug code hi·ªáu qu·∫£"
                ]
            }
        
        # X·ª≠ l√Ω c√¢u h·ªèi th√¥ng qua ChatAI service
        result = chat_ai_service.process_question(question)
        
        return result
        
    except Exception as e:
        logger.error(f"Error in ask endpoint: {e}")
        return {
            "answer": "Xin l·ªói, c√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i sau.",
            "error": str(e)
        }

@app.get("/health")
async def health_check():
    """
    Health check endpoint
    """
    try:
        # Ki·ªÉm tra k·∫øt n·ªëi AI
        test_response = chat_ai_service._call_ai("Test")
        
        return {
            "status": "healthy",
            "ai_client": "active",
            "message": "AI service is running"
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "message": "AI service is not available"
        }

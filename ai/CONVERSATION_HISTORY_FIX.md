# FIX CONVERSATION HISTORY - Tá»”NG Káº¾T

## Váº¥n Ä‘á» Ä‘Ã£ phÃ¡t hiá»‡n

Conversation history khÃ´ng hoáº¡t Ä‘á»™ng vÃ¬:

1. **Node.js Controller** khÃ´ng gá»­i `conversation_history` Ä‘áº¿n Python `/ask-stream` endpoint
2. **Python `/ask-stream` endpoint** khÃ´ng xá»­ lÃ½ `conversation_history`
3. **Python service** khÃ´ng cÃ³ method `_stream_ai_with_history` Ä‘á»ƒ stream vá»›i history

## CÃ¡c thay Ä‘á»•i Ä‘Ã£ thá»±c hiá»‡n

### 1. Node.js Controller (`api/src/controllers/chatAIController.js`)

#### Thay Ä‘á»•i 1: ThÃªm logging chi tiáº¿t
```javascript
// ThÃªm logs Ä‘á»ƒ debug conversation_history
console.log(`[ChatAI] Raw conversation_history from request:`, conversationHistory ? JSON.stringify(conversationHistory, null, 2) : 'null');
console.log(`[ChatAI] Processed conversation_history (${requestBody.conversation_history.length} messages):`, ...);
```

#### Thay Ä‘á»•i 2: Gá»­i conversation_history Ä‘áº¿n Python streaming
```javascript
// TrÆ°á»›c Ä‘Ã¢y: Chá»‰ gá»­i question
const response = await axios.post(
  `${PYTHON_AI_API_URL}/ask-stream`,
  { question: question.trim() },
  ...
);

// Sau khi sá»­a: Gá»­i cáº£ conversation_history
const streamRequestBody = {
  question: question.trim()
};

if (conversationHistory && Array.isArray(conversationHistory) && conversationHistory.length > 0) {
  streamRequestBody.conversation_history = conversationHistory.map(msg => ({
    role: msg.role || (msg.isUser ? 'user' : 'assistant'),
    content: msg.text || msg.content || msg.message || ''
  })).filter(msg => msg.content && msg.content.trim().length > 0);
}

const response = await axios.post(
  `${PYTHON_AI_API_URL}/ask-stream`,
  streamRequestBody,
  ...
);
```

### 2. Python Service (`ai/service.py`)

#### Thay Ä‘á»•i 1: Xá»­ lÃ½ conversation_history trong `/ask-stream`
```python
# TrÆ°á»›c Ä‘Ã¢y: KhÃ´ng xá»­ lÃ½ conversation_history
def generate():
    for chunk in chat_ai_service._stream_ai(prompt):
        yield chunk

# Sau khi sá»­a: Láº¥y vÃ  xá»­ lÃ½ conversation_history
conversation_history = None
if hasattr(request, 'conversation_history') and request.conversation_history:
    conversation_history = [
        {"role": msg.role, "content": msg.content}
        for msg in request.conversation_history
    ]
    logger.info(f"[/ask-stream] Received conversation_history: {len(conversation_history)} messages")

def generate():
    for chunk in chat_ai_service._stream_ai_with_history(question, conversation_history):
        yield chunk
```

#### Thay Ä‘á»•i 2: Táº¡o method `_stream_ai_with_history`
```python
def _stream_ai_with_history(self, question: str, conversation_history: Optional[List[Dict[str, str]]] = None):
    """
    Gá»i AI vá»›i streaming response vÃ  conversation history
    """
    # Build messages array
    messages = [{"role": "system", "content": "..."}]
    
    # ThÃªm conversation history náº¿u cÃ³
    if conversation_history and len(conversation_history) > 0:
        recent_history = conversation_history[-20:]
        for msg in recent_history:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            if role in ["user", "assistant"] and content:
                messages.append({"role": role, "content": content.strip()})
    
    # ThÃªm cÃ¢u há»i hiá»‡n táº¡i
    messages.append({"role": "user", "content": question})
    
    # Stream tá»« GPT
    stream = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.7,
        max_tokens=1000,
        stream=True
    )
    
    for chunk in stream:
        if chunk.choices[0].delta.content is not None:
            yield chunk.choices[0].delta.content
```

#### Thay Ä‘á»•i 3: Refactor `_stream_ai` Ä‘á»ƒ sá»­ dá»¥ng `_stream_ai_with_history`
```python
def _stream_ai(self, prompt: str):
    """
    Gá»i AI vá»›i streaming response (backward compatible - khÃ´ng cÃ³ history)
    """
    return self._stream_ai_with_history(prompt, None)
```

#### Thay Ä‘á»•i 4: ThÃªm logging chi tiáº¿t
```python
# ThÃªm logs trong táº¥t cáº£ cÃ¡c methods xá»­ lÃ½ conversation_history
logger.info(f"[/ask] Received conversation_history: {len(conversation_history)} messages")
logger.info(f"[/format-answer] Received conversation_history: {len(conversation_history)} messages")
logger.info(f"[_call_ai_with_history] Adding {len(conversation_history)} messages to conversation history")
logger.info(f"[_stream_ai_with_history] Total messages sent to GPT: {len(messages)}")
```

### 3. Frontend (`cli/src/app/core/services/chat-ai.service.ts`)

#### ThÃªm logging chi tiáº¿t Ä‘á»ƒ debug
```typescript
console.log(`[ChatAI] ===== CONVERSATION HISTORY DEBUG =====`);
console.log(`[ChatAI] Total messages in state: ${this.messagesSubject.value.length}`);
console.log(`[ChatAI] Filtered messages: ${currentMessagesBefore.length}`);
console.log(`[ChatAI] Prepared conversation history: ${conversationHistory.length} messages`);
console.log(`[ChatAI] All messages:`, JSON.stringify(conversationHistory, null, 2));
console.log(`[ChatAI] ========================================`);
```

## CÃ¡ch test

### Test 1: Sá»­ dá»¥ng test script
```bash
cd ai
python test_conversation_history.py
```

### Test 2: Sá»­ dá»¥ng curl
```bash
# CÃ¢u há»i 1
curl -X POST http://localhost:3000/api/v1/chat-ai/ask-stream \
  -H "Content-Type: application/json" \
  -d '{"question": "TÃªn tÃ´i lÃ  Nam"}'

# CÃ¢u há»i 2 vá»›i history
curl -X POST http://localhost:3000/api/v1/chat-ai/ask-stream \
  -H "Content-Type: application/json" \
  -d '{
    "question": "TÃªn tÃ´i lÃ  gÃ¬?",
    "conversation_history": [
      {"role": "user", "content": "TÃªn tÃ´i lÃ  Nam"},
      {"role": "assistant", "content": "Xin chÃ o Nam! Ráº¥t vui Ä‘Æ°á»£c lÃ m quen vá»›i báº¡n."}
    ]
  }'
```

### Test 3: Sá»­ dá»¥ng frontend
1. Má»Ÿ chat widget
2. Gá»­i: "TÃªn tÃ´i lÃ  Nam"
3. Äá»£i response
4. Gá»­i: "TÃªn tÃ´i lÃ  gÃ¬?"
5. AI sáº½ tráº£ lá»i "Nam" náº¿u conversation history hoáº¡t Ä‘á»™ng

## Káº¿t quáº£ mong Ä‘á»£i

### Logs trong Browser Console
```
[ChatAI] ===== CONVERSATION HISTORY DEBUG =====
[ChatAI] Total messages in state: 3
[ChatAI] Filtered messages: 2
[ChatAI] Prepared conversation history: 2 messages
[ChatAI] First message: {"role":"user","content":"TÃªn tÃ´i lÃ  Nam"}
[ChatAI] Last message: {"role":"assistant","content":"Xin chÃ o Nam!..."}
```

### Logs trong Node.js
```
[ChatAI Stream] Conversation history received: 2 messages
[ChatAI Stream] First message: {"role":"user","content":"TÃªn tÃ´i lÃ  Nam"}
[ChatAI Stream] Sending 2 messages to Python streaming
```

### Logs trong Python
```
[/ask-stream] Received conversation_history: 2 messages
[/ask-stream] First message: {'role': 'user', 'content': 'TÃªn tÃ´i lÃ  Nam'}
[_stream_ai_with_history] Adding 2 messages to conversation history
[_stream_ai_with_history] Total messages sent to GPT: 4
```

### Response tá»« AI
```
TÃªn báº¡n lÃ  Nam.
```

## Checklist

- [x] Node.js gá»­i conversation_history Ä‘áº¿n Python `/ask-stream`
- [x] Python `/ask-stream` nháº­n vÃ  xá»­ lÃ½ conversation_history
- [x] Python cÃ³ method `_stream_ai_with_history` Ä‘á»ƒ stream vá»›i history
- [x] ThÃªm logging chi tiáº¿t á»Ÿ táº¥t cáº£ cÃ¡c layer
- [x] Táº¡o test script Ä‘á»ƒ kiá»ƒm tra
- [x] Táº¡o documentation

## LÆ°u Ã½

1. **Giá»›i háº¡n history**: Chá»‰ láº¥y 20 messages gáº§n nháº¥t Ä‘á»ƒ trÃ¡nh token limit
2. **Backward compatible**: Method `_stream_ai` váº«n hoáº¡t Ä‘á»™ng cho code cÅ©
3. **Error handling**: CÃ³ fallback náº¿u conversation_history khÃ´ng há»£p lá»‡
4. **Logging**: Äáº§y Ä‘á»§ logs Ä‘á»ƒ debug náº¿u cÃ³ váº¥n Ä‘á»

## Restart services

Sau khi thay Ä‘á»•i code, cáº§n restart cáº£ 2 services:

```bash
# Restart Python service
cd ai
# Ctrl+C Ä‘á»ƒ stop
python start.py

# Restart Node.js service
cd api
# Ctrl+C Ä‘á»ƒ stop
npm start
```

## Kiá»ƒm tra

Sau khi restart, cháº¡y test script:
```bash
cd ai
python test_conversation_history.py
```

Náº¿u tháº¥y:
```
âœ… SUCCESS: AI nhá»› Ä‘Æ°á»£c tÃªn!
ğŸ‰ CONVERSATION HISTORY HOáº T Äá»˜NG Tá»T!
```

ThÃ¬ conversation history Ä‘Ã£ hoáº¡t Ä‘á»™ng!
